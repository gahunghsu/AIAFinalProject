{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import necessary libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gaga.hsu\\Miniconda3\\envs\\openai\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from transformers import GPT2TokenizerFast\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting api key and model name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#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\n",
    "openai.api_key = \"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\"\n",
    "COMPLETIONS_MODEL = \"babbage\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用openai工具，來看trainning data有什麼可以調整的地方"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!openai tools fine_tunes.prepare_data -f test.jsonl -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_prepared.jsonl', 'r', encoding='utf8') as f:\n",
    "    content = f.read()\n",
    "    print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 上傳Training data到openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_prepared_0515.jsonl\", 'r', encoding='utf8') as f:\n",
    "  response = openai.File.create(file=f, purpose='fine-tune')\n",
    "  print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建立fine tune job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model babbage is optional parameter\n",
    "response = openai.FineTune.create(training_file=\"file-I2h9fjDssfdtTGviuwh2Rn6I\", model=COMPLETIONS_MODEL)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.events[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_events = openai.FineTune.list_events(id=response.id)\n",
    "fine_tune_events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用model id來看fine tune的過程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<FineTune fine-tune id=ft-tAQHNK9QLPy2zwr9yI3GytbS at 0x24c084b35e0> JSON: {\n",
       "  \"created_at\": 1684135455,\n",
       "  \"events\": [\n",
       "    {\n",
       "      \"created_at\": 1684135455,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Created fine-tune: ft-tAQHNK9QLPy2zwr9yI3GytbS\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1684135486,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune costs $0.16\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1684135486,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune enqueued. Queue number: 3\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1684135921,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune is in the queue. Queue number: 2\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1684135922,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune is in the queue. Queue number: 1\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1684136143,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune is in the queue. Queue number: 0\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1684136167,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune started\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1684136552,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Completed epoch 1/4\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1684137280,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Completed epoch 3/4\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1684137664,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Uploaded model: babbage:ft-taiwan-ai-academy-foundation-2023-05-15-08-01-04\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1684137665,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Uploaded result file: file-zShMXzZ0HtOWLMWosVNkK9DQ\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1684137666,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune succeeded\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    }\n",
       "  ],\n",
       "  \"fine_tuned_model\": \"babbage:ft-taiwan-ai-academy-foundation-2023-05-15-08-01-04\",\n",
       "  \"hyperparams\": {\n",
       "    \"batch_size\": 2,\n",
       "    \"learning_rate_multiplier\": 0.1,\n",
       "    \"n_epochs\": 4,\n",
       "    \"prompt_loss_weight\": 0.01\n",
       "  },\n",
       "  \"id\": \"ft-tAQHNK9QLPy2zwr9yI3GytbS\",\n",
       "  \"model\": \"babbage\",\n",
       "  \"object\": \"fine-tune\",\n",
       "  \"organization_id\": \"org-EkieKrMNeYQoV4o2eJCWUhJa\",\n",
       "  \"result_files\": [\n",
       "    {\n",
       "      \"bytes\": 179823,\n",
       "      \"created_at\": 1684137665,\n",
       "      \"filename\": \"compiled_results.csv\",\n",
       "      \"id\": \"file-zShMXzZ0HtOWLMWosVNkK9DQ\",\n",
       "      \"object\": \"file\",\n",
       "      \"purpose\": \"fine-tune-results\",\n",
       "      \"status\": \"processed\",\n",
       "      \"status_details\": null\n",
       "    }\n",
       "  ],\n",
       "  \"status\": \"succeeded\",\n",
       "  \"training_files\": [\n",
       "    {\n",
       "      \"bytes\": 185615,\n",
       "      \"created_at\": 1684135405,\n",
       "      \"filename\": \"file\",\n",
       "      \"id\": \"file-I2h9fjDssfdtTGviuwh2Rn6I\",\n",
       "      \"object\": \"file\",\n",
       "      \"purpose\": \"fine-tune\",\n",
       "      \"status\": \"processed\",\n",
       "      \"status_details\": null\n",
       "    }\n",
       "  ],\n",
       "  \"updated_at\": 1684137666,\n",
       "  \"validation_files\": []\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve_response = openai.FineTune.retrieve(\"ft-tAQHNK9QLPy2zwr9yI3GytbS\")\n",
    "retrieve_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 取得fine truned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'babbage:ft-taiwan-ai-academy-foundation-2023-05-15-08-01-04'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_tuned_model = retrieve_response.fine_tuned_model\n",
    "fine_tuned_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用 openai infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "有没有卖汽水 ->  7 from product where 1 = '汽水'\n"
     ]
    }
   ],
   "source": [
    "promps = []\n",
    "promps.append(\"有没有卖汽水 ->\")\n",
    "\n",
    "for new_prompt in promps:\n",
    "\n",
    "  answer = openai.Completion.create(\n",
    "    model=fine_tuned_model,\n",
    "    prompt=new_prompt,\n",
    "    max_tokens=50,\n",
    "    temperature=0.1\n",
    "  )\n",
    "\n",
    "  # 使用 \"\\n\" 作為分割符號，將文字串分割成多個部分\n",
    "  parts = answer['choices'][0]['text'].split(\"\\n\")\n",
    "\n",
    "  # 取得第一個部分\n",
    "  first_part = parts[0]\n",
    "\n",
    "  # 輸出結果\n",
    "  print(new_prompt, first_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"select\" + first_part\n",
    "sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select location from product where sub_category = '汽水'\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def map_query(sql_query, table_schema):\n",
    "    # 提取数字和条件值\n",
    "    numbers = re.findall(r'\\b\\d+\\b', sql_query)\n",
    "    condition_value = re.findall(r\"'([^']*)'\", sql_query)[0]\n",
    "    \n",
    "    # 替换数字和条件值\n",
    "    for number in numbers:\n",
    "        number = int(number)\n",
    "        if number in table_schema:\n",
    "            field = table_schema[number]\n",
    "            sql_query = re.sub(r'\\b{}\\b'.format(number), field, sql_query)\n",
    "    \n",
    "    sql_query = re.sub(r\"{}\\s*=\\s*'\\b([^']+)\\b'\".format(table_schema[1]), \"{} = '{}'\".format(table_schema[1], condition_value), sql_query)\n",
    "    \n",
    "    return sql_query\n",
    "\n",
    "# 测试示例\n",
    "sql_query = \"select 7 from product where 1 = '汽水'\"\n",
    "table_schema = {0: \"main_category\", 1: \"sub_category\", 2: \"product_type\", 3: \"weight\", 4: \"item\", 5: \"price\", 6: \"unit_price\", 7: \"location\"}\n",
    "\n",
    "new_query = map_query(sql_query, table_schema)\n",
    "print(new_query)  # 输出：select location from product where sub_category = '汽水'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 計算training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "created_at = 1684135455\n",
    "updated_at = 1684137666\n",
    "\n",
    "# 将时间戳转换为datetime对象\n",
    "created_dt = datetime.datetime.fromtimestamp(created_at)\n",
    "updated_dt = datetime.datetime.fromtimestamp(updated_at)\n",
    "\n",
    "# 计算时间差异\n",
    "time_diff = updated_dt - created_dt\n",
    "\n",
    "# 获取时间差异的分钟数\n",
    "minutes_diff = time_diff.total_seconds() // 60\n",
    "\n",
    "print(f\"相隔分钟数：{minutes_diff} 分钟\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 計算training data的token數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import json\n",
    "\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "jsonl_file = 'test.jsonl'\n",
    "num_tokens = 0\n",
    "with open(jsonl_file, 'r', encoding='utf-8') as file:\n",
    "    line = file.readline()\n",
    "    while line:\n",
    "        json_obj = json.loads(line)\n",
    "        # 在這裡對每個 JSON 物件進行處理\n",
    "        # ...\n",
    "        line = file.readline()\n",
    "        num_tokens += num_tokens_from_string(line, \"r50k_base\")\n",
    "print(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'table_id': '4d25e6403aaa11e9bdbbf40f24344a08', 'question': '捷成股为什么要增发', 'sql': {'agg': [0], 'cond_conn_op': 0, 'sel': [7], 'conds': [[1, 2, '捷成股份']]}}\n",
      "in if\n",
      "{'table_id': '4d25e6403aaa11e9bdbbf40f24344a08', 'question': '捷成股为什么要增发', 'sql': {'agg': 0, 'sel': 7, 'conds': [[1, 2, '捷成股份']]}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "data = []\n",
    "\n",
    "with open('test.jsonl', 'r' , encoding='utf-8') as jsonl_file:\n",
    "    lines_jl = jsonl_file.readlines()\n",
    "\n",
    "    for line in lines_jl:\n",
    "        line = line.strip()  # 去除首尾空格和换行符\n",
    "        json_obj = json.loads(line)  # 将字符串转换为字典对象\n",
    "        print(json_obj)\n",
    "        \n",
    "        if len(json_obj[\"sql\"][\"agg\"])==1 and json_obj[\"sql\"][\"cond_conn_op\"] == 0 :\n",
    "            json_obj[\"sql\"][\"agg\"]=0\n",
    "            json_obj[\"sql\"][\"sel\"]=json_obj[\"sql\"][\"sel\"][0]\n",
    "            value = json_obj[\"sql\"].pop('cond_conn_op', None)\n",
    "        print(json_obj)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('openai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "18eb296bc6e568f6fe2bf45e139e79095bd5cb3d141fe3c8a39ac62ac1897f7b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
